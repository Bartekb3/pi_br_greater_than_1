{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f30df1",
   "metadata": {},
   "source": [
    "UWAGA - poniżej również kod do testów na cpu. W celu lokalnych testów warto zrobić tymczasowy katalog z jednym datasetem, na podstawie którego będziemy porównywać czas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689d9d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_datasets = './test_data/small/'\n",
    "path_to_datasets = '../test_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cbe5fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czy GPU działa? True\n",
      "GPU: b'NVIDIA GeForce RTX 4050 Laptop GPU'\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "print(\"Czy GPU działa?\", cp.cuda.is_available())\n",
    "print(\"GPU:\", cp.cuda.runtime.getDeviceProperties(0)['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e025ef",
   "metadata": {
    "id": "OYsfE7F4XLpL"
   },
   "source": [
    "# Training on cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b74c9ba8",
   "metadata": {
    "id": "CcdwAEZiXR3W"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b10668e1",
   "metadata": {
    "id": "e63l5DYpXRoQ"
   },
   "outputs": [],
   "source": [
    "rf_100 =    ('RF', RandomForestRegressor(random_state=123, n_jobs=-1, n_estimators=100))\n",
    "rf_200 =    ('RF[200]', RandomForestRegressor(random_state=123, n_jobs=-1,  n_estimators=200))\n",
    "rf_500 =    ('RF[500]', RandomForestRegressor(random_state=123, n_jobs=-1, n_estimators=500))\n",
    "rf_md_10 =  ('RF[md10]', RandomForestRegressor(random_state=123, n_jobs=-1, max_depth=10))\n",
    "rf_md_15 =  ('RF[md15]', RandomForestRegressor(random_state=123, n_jobs=-1, max_depth=15))\n",
    "rf_md_20 =  ('RF[md20]', RandomForestRegressor(random_state=123, n_jobs=-1, max_depth=20))\n",
    "rf_md_25 =  ('RF[md25]', RandomForestRegressor(random_state=123, n_jobs=-1, max_depth=25))\n",
    "rf_mss_3 =  ('RF[mss3]', RandomForestRegressor(random_state=123, n_jobs=-1, min_samples_split=3))\n",
    "rf_mss_4 =  ('RF[mss4]', RandomForestRegressor(random_state=123, n_jobs=-1, min_samples_split=4))\n",
    "rf_mss_6 =  ('RF[mss6]', RandomForestRegressor(random_state=123, n_jobs=-1, min_samples_split=6))\n",
    "rf_mss_8 =  ('RF[mss8]', RandomForestRegressor(random_state=123, n_jobs=-1, min_samples_split=8))\n",
    "rf_msl_2 =  ('RF[msl2]', RandomForestRegressor(random_state=123, n_jobs=-1, min_samples_leaf=2))\n",
    "rf_msl_3 =  ('RF[msl3]', RandomForestRegressor(random_state=123, n_jobs=-1, min_samples_leaf=3))\n",
    "rf_msl_4 =  ('RF[msl4]', RandomForestRegressor(random_state=123, n_jobs=-1, min_samples_leaf=4))\n",
    "rf_msl_5 =  ('RF[msl5]', RandomForestRegressor(random_state=123, n_jobs=-1, min_samples_leaf=5))\n",
    "rf_mf_log = ('RF[mfLog2]', RandomForestRegressor(random_state=123, n_jobs=-1, max_features=\"log2\"))\n",
    "rf_mf_all = ('RF[mfAll]', RandomForestRegressor(random_state=123, n_jobs=-1, max_features=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "543b0d90",
   "metadata": {
    "id": "UpQdZYRPXVaU"
   },
   "outputs": [],
   "source": [
    "max_samples = [0.2, 0.6, 0.8, 1, 1.2, 2, 3, 4, 5]\n",
    "forests = [rf_100, rf_200, rf_500, rf_md_10, rf_md_15, rf_md_20, rf_md_25, rf_mss_3, rf_mss_4, rf_mss_6, rf_mss_8,\n",
    "        rf_msl_2, rf_msl_3, rf_msl_4, rf_msl_5, rf_mf_log, rf_mf_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5205306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X_train(X_tra, y_tra, max_sample):\n",
    "    if max_sample <= 1:\n",
    "        return X_tra, y_tra\n",
    "    elif 1 < max_sample < 2:\n",
    "        return np.tile(X_tra, (2, 1)), np.tile(y_tra, 2)\n",
    "    else:\n",
    "        return np.tile(X_tra, (max_sample, 1)), np.tile(y_tra, max_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = []\n",
    "for filename in os.listdir(path_to_datasets):\n",
    "    full_path = os.path.join(path_to_datasets, filename)\n",
    "    dataset_paths.append(full_path)\n",
    "results = {'dataset' : [],\n",
    "           'bootstrap_rate': [],\n",
    "           'rf' : [],\n",
    "           'cv_mse_scores' : [],\n",
    "           'mean_mse' : [],\n",
    "           'std_mse' : []}\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "cvsplit = RepeatedKFold(n_splits=2, n_repeats=200, random_state=42)\n",
    "total_datasets = len(dataset_paths)\n",
    "total_ms = len(max_samples)\n",
    "total_forests = len(forests)\n",
    "total_folds = 2 * 200  # n_splits * n_repeats\n",
    "\n",
    "pd.read_csv(dataset_paths[0]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b28b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from sklearn.base import clone\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "results = []\n",
    "\n",
    "def run_single_fold(model, ms, X, y, train_index, test_index, fold_idx, dataset_name):\n",
    "    start_time = time.time()\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    X_tr, y_tr = make_X_train(X_train, y_train, ms)\n",
    "\n",
    "    model = clone(model)\n",
    "    model.max_samples = None if ms >= 1 and ms != 1.2 else (0.6 if ms == 1.2 else ms)\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    y_hat = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_hat)\n",
    "\n",
    "    elapsed_time = timedelta(seconds=(time.time() - start_time))\n",
    "\n",
    "    return {\n",
    "        'dataset': dataset_name,\n",
    "        'model': 'RF',\n",
    "        'max_samples': ms,\n",
    "        'fold': fold_idx,\n",
    "        'mse': mse,\n",
    "        'elapsed_time': elapsed_time\n",
    "    }\n",
    "\n",
    "for dataset_path in dataset_paths:\n",
    "    dataset_name = os.path.basename(dataset_path).replace('.csv', '')\n",
    "    print(f\"Processing dataset: {dataset_name}\")\n",
    "    \n",
    "    data = pd.read_csv(dataset_path)\n",
    "    X = data.drop('target', axis=1).values\n",
    "    y = data['target'].values\n",
    "    \n",
    "    cvsplit = RepeatedKFold(n_splits=10, n_repeats=10, random_state=123)\n",
    "    \n",
    "    for ms in max_samples:\n",
    "        print(f\"max_samples = {ms}\")\n",
    "        \n",
    "        fold_results = Parallel(n_jobs=-1)(\n",
    "            delayed(run_single_fold)(\n",
    "                rf_100[1], ms, X, y, train_idx, test_idx, fold_idx, dataset_name\n",
    "            )\n",
    "            for fold_idx, (train_idx, test_idx) in enumerate(cvsplit.split(X, y), 1)\n",
    "        )\n",
    "        results.extend(fold_results)\n",
    "    \n",
    "    # Save after each dataset as per original logic\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(f'wyniki_{dataset_name}_bb.csv', index=False)\n",
    "    print(f\"Wyniki zapisane dla {dataset_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4019cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(f'Total elapsed time: {timedelta(seconds=end_time - start_time)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data sources:\n",
    "- [Taxi price](https://www.kaggle.com/datasets/denkuznetz/taxi-price-prediction/data?fbclid=IwZXh0bgNhZW0CMTAAAR3EXwfcJrO4pqnY2pId6K4qb2sd01_YLdKmfEKlIZ8bxhvxc2iwQKw01ik_aem_yNsb3V7ymqavEDGZfZZBJA)\n",
    "- [Flood Prediction](https://www.kaggle.com/datasets/naiyakhalid/flood-prediction-dataset?fbclid=IwZXh0bgNhZW0CMTAAAR31KS5Uu8KLo3FP9L0kwUM1iDdiYWZCD2q3fuxnrhup8UB4D-n5KLOinSg_aem_eziiiOqts_lvLdyq2uftIQ)\n",
    "- [Airfoil Self-Noise](https://archive.ics.uci.edu/dataset/291/airfoil+self+noise?fbclid=IwZXh0bgNhZW0CMTAAAR1qsj7CYd84jygC5CQnGTuBnMqopmtgGYAFnm3EtJaz0BBv735Dhu2fut8_aem_lBvbJTztOR47e3Vk2nuNOw)\n",
    "- [Superconductivty Data](https://archive.ics.uci.edu/dataset/464/superconductivty+data?fbclid=IwZXh0bgNhZW0CMTAAAR3dr3Eitf5ZHCekr4hKhaqapt2sgtuSCpSFWogqI5F0o9bnE9edFQro_mg_aem_CYa2w2f-668q3LO-k_DElg)\n",
    "- [SUPPORT2](https://archive.ics.uci.edu/dataset/880/support2?fbclid=IwZXh0bgNhZW0CMTAAAR3dr3Eitf5ZHCekr4hKhaqapt2sgtuSCpSFWogqI5F0o9bnE9edFQro_mg_aem_CYa2w2f-668q3LO-k_DElg)\n",
    "- [Metro Interstate Traffic Volume](https://archive.ics.uci.edu/dataset/492/metro+interstate+traffic+volume?fbclid=IwZXh0bgNhZW0CMTAAAR3dr3Eitf5ZHCekr4hKhaqapt2sgtuSCpSFWogqI5F0o9bnE9edFQro_mg_aem_CYa2w2f-668q3LO-k_DElg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>angle_of_attack</th>\n",
       "      <th>chord-length</th>\n",
       "      <th>free-stream-velocity</th>\n",
       "      <th>suction-side-displacement-thickness</th>\n",
       "      <th>scaled-sound-pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>126.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frequency  angle_of_attack  chord-length  free-stream-velocity  \\\n",
       "0        800              0.0        0.3048                  71.3   \n",
       "1       1000              0.0        0.3048                  71.3   \n",
       "2       1250              0.0        0.3048                  71.3   \n",
       "3       1600              0.0        0.3048                  71.3   \n",
       "4       2000              0.0        0.3048                  71.3   \n",
       "\n",
       "   suction-side-displacement-thickness  scaled-sound-pressure  \n",
       "0                             0.002663                126.201  \n",
       "1                             0.002663                125.201  \n",
       "2                             0.002663                125.951  \n",
       "3                             0.002663                127.591  \n",
       "4                             0.002663                127.461  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('./data/airfoil_self_noise.dat', sep='\\\\s+')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonsoonIntensity</th>\n",
       "      <th>TopographyDrainage</th>\n",
       "      <th>RiverManagement</th>\n",
       "      <th>Deforestation</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>ClimateChange</th>\n",
       "      <th>DamsQuality</th>\n",
       "      <th>Siltation</th>\n",
       "      <th>AgriculturalPractices</th>\n",
       "      <th>Encroachments</th>\n",
       "      <th>...</th>\n",
       "      <th>DrainageSystems</th>\n",
       "      <th>CoastalVulnerability</th>\n",
       "      <th>Landslides</th>\n",
       "      <th>Watersheds</th>\n",
       "      <th>DeterioratingInfrastructure</th>\n",
       "      <th>PopulationScore</th>\n",
       "      <th>WetlandLoss</th>\n",
       "      <th>InadequatePlanning</th>\n",
       "      <th>PoliticalFactors</th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MonsoonIntensity  TopographyDrainage  RiverManagement  Deforestation  \\\n",
       "0                 3                   8                6              6   \n",
       "1                 8                   4                5              7   \n",
       "2                 3                  10                4              1   \n",
       "3                 4                   4                2              7   \n",
       "4                 3                   7                5              2   \n",
       "\n",
       "   Urbanization  ClimateChange  DamsQuality  Siltation  AgriculturalPractices  \\\n",
       "0             4              4            6          2                      3   \n",
       "1             7              9            1          5                      5   \n",
       "2             7              5            4          7                      4   \n",
       "3             3              4            1          4                      6   \n",
       "4             5              8            5          2                      7   \n",
       "\n",
       "   Encroachments  ...  DrainageSystems  CoastalVulnerability  Landslides  \\\n",
       "0              2  ...               10                     7           4   \n",
       "1              4  ...                9                     2           6   \n",
       "2              9  ...                7                     4           4   \n",
       "3              4  ...                4                     2           6   \n",
       "4              5  ...                7                     6           5   \n",
       "\n",
       "   Watersheds  DeterioratingInfrastructure  PopulationScore  WetlandLoss  \\\n",
       "0           2                            3                4            3   \n",
       "1           2                            1                1            9   \n",
       "2           8                            6                1            8   \n",
       "3           6                            8                8            6   \n",
       "4           3                            3                4            4   \n",
       "\n",
       "   InadequatePlanning  PoliticalFactors  FloodProbability  \n",
       "0                   2                 6             0.450  \n",
       "1                   1                 3             0.475  \n",
       "2                   3                 6             0.515  \n",
       "3                   6                10             0.520  \n",
       "4                   3                 4             0.475  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('./data/flood.csv')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_time</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>288.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>2012-10-02 09:00:00</td>\n",
       "      <td>5545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>289.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2012-10-02 10:00:00</td>\n",
       "      <td>4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>289.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2012-10-02 11:00:00</td>\n",
       "      <td>4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>290.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2012-10-02 12:00:00</td>\n",
       "      <td>5026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>291.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2012-10-02 13:00:00</td>\n",
       "      <td>4918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  holiday    temp  rain_1h  snow_1h  clouds_all weather_main  \\\n",
       "0     NaN  288.28      0.0      0.0          40       Clouds   \n",
       "1     NaN  289.36      0.0      0.0          75       Clouds   \n",
       "2     NaN  289.58      0.0      0.0          90       Clouds   \n",
       "3     NaN  290.13      0.0      0.0          90       Clouds   \n",
       "4     NaN  291.14      0.0      0.0          75       Clouds   \n",
       "\n",
       "  weather_description            date_time  traffic_volume  \n",
       "0    scattered clouds  2012-10-02 09:00:00            5545  \n",
       "1       broken clouds  2012-10-02 10:00:00            4516  \n",
       "2     overcast clouds  2012-10-02 11:00:00            4767  \n",
       "3     overcast clouds  2012-10-02 12:00:00            5026  \n",
       "4       broken clouds  2012-10-02 13:00:00            4918  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv('./data/Metro_Interstate_Traffic_Volume.csv')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.862692</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.116612</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.062396</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>31.794921</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.219783</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.066221</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.437059</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>92.729214</td>\n",
       "      <td>58.518416</td>\n",
       "      <td>73.132787</td>\n",
       "      <td>36.396602</td>\n",
       "      <td>1.449309</td>\n",
       "      <td>1.057755</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>36.161939</td>\n",
       "      <td>47.094633</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>1.888175</td>\n",
       "      <td>2.210679</td>\n",
       "      <td>1.557113</td>\n",
       "      <td>1.047221</td>\n",
       "      <td>2</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.468606</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.885242</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.122509</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>0.975980</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>35.741099</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.232679</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.029175</td>\n",
       "      <td>1</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.444697</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.873967</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.119560</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.022291</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>33.768010</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.264286</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.226222</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.048834</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.440952</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.840143</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.110716</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.129224</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>27.848743</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.242857</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.206963</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.096052</td>\n",
       "      <td>1</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.428809</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
       "0                   4         88.944468             57.862692   \n",
       "1                   5         92.729214             58.518416   \n",
       "2                   4         88.944468             57.885242   \n",
       "3                   4         88.944468             57.873967   \n",
       "4                   4         88.944468             57.840143   \n",
       "\n",
       "   gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
       "0          66.361592              36.116612             1.181795   \n",
       "1          73.132787              36.396602             1.449309   \n",
       "2          66.361592              36.122509             1.181795   \n",
       "3          66.361592              36.119560             1.181795   \n",
       "4          66.361592              36.110716             1.181795   \n",
       "\n",
       "   wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
       "0                 1.062396          122.90607              31.794921   \n",
       "1                 1.057755          122.90607              36.161939   \n",
       "2                 0.975980          122.90607              35.741099   \n",
       "3                 1.022291          122.90607              33.768010   \n",
       "4                 1.129224          122.90607              27.848743   \n",
       "\n",
       "   std_atomic_mass  ...  wtd_mean_Valence  gmean_Valence  wtd_gmean_Valence  \\\n",
       "0        51.968828  ...          2.257143       2.213364           2.219783   \n",
       "1        47.094633  ...          2.257143       1.888175           2.210679   \n",
       "2        51.968828  ...          2.271429       2.213364           2.232679   \n",
       "3        51.968828  ...          2.264286       2.213364           2.226222   \n",
       "4        51.968828  ...          2.242857       2.213364           2.206963   \n",
       "\n",
       "   entropy_Valence  wtd_entropy_Valence  range_Valence  wtd_range_Valence  \\\n",
       "0         1.368922             1.066221              1           1.085714   \n",
       "1         1.557113             1.047221              2           1.128571   \n",
       "2         1.368922             1.029175              1           1.114286   \n",
       "3         1.368922             1.048834              1           1.100000   \n",
       "4         1.368922             1.096052              1           1.057143   \n",
       "\n",
       "   std_Valence  wtd_std_Valence  critical_temp  \n",
       "0     0.433013         0.437059           29.0  \n",
       "1     0.632456         0.468606           26.0  \n",
       "2     0.433013         0.444697           19.0  \n",
       "3     0.433013         0.440952           22.0  \n",
       "4     0.433013         0.428809           23.0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"./data/superconductivity.csv\")\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>death</th>\n",
       "      <th>sex</th>\n",
       "      <th>hospdead</th>\n",
       "      <th>slos</th>\n",
       "      <th>d.time</th>\n",
       "      <th>dzgroup</th>\n",
       "      <th>dzclass</th>\n",
       "      <th>num.co</th>\n",
       "      <th>edu</th>\n",
       "      <th>...</th>\n",
       "      <th>crea</th>\n",
       "      <th>sod</th>\n",
       "      <th>ph</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bun</th>\n",
       "      <th>urine</th>\n",
       "      <th>adlp</th>\n",
       "      <th>adls</th>\n",
       "      <th>sfdm2</th>\n",
       "      <th>adlsc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.84998</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2029</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.199951</td>\n",
       "      <td>141.0</td>\n",
       "      <td>7.459961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.33899</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Cirrhosis</td>\n",
       "      <td>COPD/CHF/Cirrhosis</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>132.0</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;2 mo. follow-up</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.74698</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>47</td>\n",
       "      <td>Cirrhosis</td>\n",
       "      <td>COPD/CHF/Cirrhosis</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>7.459961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;2 mo. follow-up</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.38498</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799927</td>\n",
       "      <td>139.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no(M2 and SIP pres)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>79.88495</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2029</td>\n",
       "      <td>ARF/MOSF w/Sepsis</td>\n",
       "      <td>ARF/MOSF</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799927</td>\n",
       "      <td>143.0</td>\n",
       "      <td>7.509766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no(M2 and SIP pres)</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  death     sex  hospdead  slos  d.time            dzgroup  \\\n",
       "1  62.84998      0    male         0     5    2029        Lung Cancer   \n",
       "2  60.33899      1  female         1     4       4          Cirrhosis   \n",
       "3  52.74698      1  female         0    17      47          Cirrhosis   \n",
       "4  42.38498      1  female         0     3     133        Lung Cancer   \n",
       "5  79.88495      0  female         0    16    2029  ARF/MOSF w/Sepsis   \n",
       "\n",
       "              dzclass  num.co   edu  ...      crea    sod        ph  glucose  \\\n",
       "1              Cancer       0  11.0  ...  1.199951  141.0  7.459961      NaN   \n",
       "2  COPD/CHF/Cirrhosis       2  12.0  ...  5.500000  132.0  7.250000      NaN   \n",
       "3  COPD/CHF/Cirrhosis       2  12.0  ...  2.000000  134.0  7.459961      NaN   \n",
       "4              Cancer       2  11.0  ...  0.799927  139.0       NaN      NaN   \n",
       "5            ARF/MOSF       1   NaN  ...  0.799927  143.0  7.509766      NaN   \n",
       "\n",
       "   bun  urine adlp  adls                sfdm2  adlsc  \n",
       "1  NaN    NaN  7.0   7.0                  NaN    7.0  \n",
       "2  NaN    NaN  NaN   1.0     <2 mo. follow-up    1.0  \n",
       "3  NaN    NaN  1.0   0.0     <2 mo. follow-up    0.0  \n",
       "4  NaN    NaN  0.0   0.0  no(M2 and SIP pres)    0.0  \n",
       "5  NaN    NaN  NaN   2.0  no(M2 and SIP pres)    2.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"./data/support2.csv\")\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip_Distance_km</th>\n",
       "      <th>Time_of_Day</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Passenger_Count</th>\n",
       "      <th>Traffic_Conditions</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Base_Fare</th>\n",
       "      <th>Per_Km_Rate</th>\n",
       "      <th>Per_Minute_Rate</th>\n",
       "      <th>Trip_Duration_Minutes</th>\n",
       "      <th>Trip_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.35</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Clear</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.32</td>\n",
       "      <td>53.82</td>\n",
       "      <td>36.2624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.59</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High</td>\n",
       "      <td>Clear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.43</td>\n",
       "      <td>40.57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.87</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High</td>\n",
       "      <td>Clear</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.15</td>\n",
       "      <td>37.27</td>\n",
       "      <td>52.9032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.33</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.15</td>\n",
       "      <td>116.81</td>\n",
       "      <td>36.4698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>3.0</td>\n",
       "      <td>High</td>\n",
       "      <td>Clear</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.32</td>\n",
       "      <td>22.64</td>\n",
       "      <td>15.6180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trip_Distance_km Time_of_Day Day_of_Week  Passenger_Count  \\\n",
       "0             19.35     Morning     Weekday              3.0   \n",
       "1             47.59   Afternoon     Weekday              1.0   \n",
       "2             36.87     Evening     Weekend              1.0   \n",
       "3             30.33     Evening     Weekday              4.0   \n",
       "4               NaN     Evening     Weekday              3.0   \n",
       "\n",
       "  Traffic_Conditions Weather  Base_Fare  Per_Km_Rate  Per_Minute_Rate  \\\n",
       "0                Low   Clear       3.56         0.80             0.32   \n",
       "1               High   Clear        NaN         0.62             0.43   \n",
       "2               High   Clear       2.70         1.21             0.15   \n",
       "3                Low     NaN       3.48         0.51             0.15   \n",
       "4               High   Clear       2.93         0.63             0.32   \n",
       "\n",
       "   Trip_Duration_Minutes  Trip_Price  \n",
       "0                  53.82     36.2624  \n",
       "1                  40.57         NaN  \n",
       "2                  37.27     52.9032  \n",
       "3                 116.81     36.4698  \n",
       "4                  22.64     15.6180  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = pd.read_csv(\"./data/taxi_trip_pricing.csv\")\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulate special columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df3 - change datetime and holidays column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_datetime_features(df, datetime_col):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    print(f\"Processing datetime column: {datetime_col}\")\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df_copy[datetime_col]):\n",
    "        df_copy[datetime_col] = pd.to_datetime(df_copy[datetime_col], errors='coerce')\n",
    "    \n",
    "    df_copy[f'{datetime_col}_year'] = df_copy[datetime_col].dt.year\n",
    "    df_copy[f'{datetime_col}_month'] = df_copy[datetime_col].dt.month\n",
    "    df_copy[f'{datetime_col}_day'] = df_copy[datetime_col].dt.day\n",
    "    df_copy[f'{datetime_col}_hour'] = df_copy[datetime_col].dt.hour\n",
    "    df_copy[f'{datetime_col}_dayofweek'] = df_copy[datetime_col].dt.dayofweek\n",
    "    df_copy[f'{datetime_col}_quarter'] = df_copy[datetime_col].dt.quarter\n",
    "    df_copy[f'{datetime_col}_is_weekend'] = df_copy[datetime_col].dt.dayofweek >= 5\n",
    "    \n",
    "    df_copy[f'{datetime_col}_month_sin'] = np.sin(2 * np.pi * df_copy[datetime_col].dt.month / 12)\n",
    "    df_copy[f'{datetime_col}_month_cos'] = np.cos(2 * np.pi * df_copy[datetime_col].dt.month / 12)\n",
    "    df_copy[f'{datetime_col}_hour_sin'] = np.sin(2 * np.pi * df_copy[datetime_col].dt.hour / 24)\n",
    "    df_copy[f'{datetime_col}_hour_cos'] = np.cos(2 * np.pi * df_copy[datetime_col].dt.hour / 24)\n",
    "    df_copy[f'{datetime_col}_dayofweek_sin'] = np.sin(2 * np.pi * df_copy[datetime_col].dt.dayofweek / 7)\n",
    "    df_copy[f'{datetime_col}_dayofweek_cos'] = np.cos(2 * np.pi * df_copy[datetime_col].dt.dayofweek / 7)\n",
    "    \n",
    "    df_copy = df_copy.drop(columns=[datetime_col])\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing datetime column: date_time\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>date_time_year</th>\n",
       "      <th>date_time_month</th>\n",
       "      <th>...</th>\n",
       "      <th>date_time_hour</th>\n",
       "      <th>date_time_dayofweek</th>\n",
       "      <th>date_time_quarter</th>\n",
       "      <th>date_time_is_weekend</th>\n",
       "      <th>date_time_month_sin</th>\n",
       "      <th>date_time_month_cos</th>\n",
       "      <th>date_time_hour_sin</th>\n",
       "      <th>date_time_hour_cos</th>\n",
       "      <th>date_time_dayofweek_sin</th>\n",
       "      <th>date_time_dayofweek_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>288.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>5545</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>289.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>4516</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>289.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>4767</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>290.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>5026</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>291.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>4918</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  holiday    temp  rain_1h  snow_1h  clouds_all weather_main  \\\n",
       "0     NaN  288.28      0.0      0.0          40       Clouds   \n",
       "1     NaN  289.36      0.0      0.0          75       Clouds   \n",
       "2     NaN  289.58      0.0      0.0          90       Clouds   \n",
       "3     NaN  290.13      0.0      0.0          90       Clouds   \n",
       "4     NaN  291.14      0.0      0.0          75       Clouds   \n",
       "\n",
       "  weather_description  traffic_volume  date_time_year  date_time_month  ...  \\\n",
       "0    scattered clouds            5545            2012               10  ...   \n",
       "1       broken clouds            4516            2012               10  ...   \n",
       "2     overcast clouds            4767            2012               10  ...   \n",
       "3     overcast clouds            5026            2012               10  ...   \n",
       "4       broken clouds            4918            2012               10  ...   \n",
       "\n",
       "   date_time_hour  date_time_dayofweek  date_time_quarter  \\\n",
       "0               9                    1                  4   \n",
       "1              10                    1                  4   \n",
       "2              11                    1                  4   \n",
       "3              12                    1                  4   \n",
       "4              13                    1                  4   \n",
       "\n",
       "   date_time_is_weekend  date_time_month_sin  date_time_month_cos  \\\n",
       "0                 False            -0.866025                  0.5   \n",
       "1                 False            -0.866025                  0.5   \n",
       "2                 False            -0.866025                  0.5   \n",
       "3                 False            -0.866025                  0.5   \n",
       "4                 False            -0.866025                  0.5   \n",
       "\n",
       "   date_time_hour_sin  date_time_hour_cos  date_time_dayofweek_sin  \\\n",
       "0        7.071068e-01           -0.707107                 0.781831   \n",
       "1        5.000000e-01           -0.866025                 0.781831   \n",
       "2        2.588190e-01           -0.965926                 0.781831   \n",
       "3        1.224647e-16           -1.000000                 0.781831   \n",
       "4       -2.588190e-01           -0.965926                 0.781831   \n",
       "\n",
       "   date_time_dayofweek_cos  \n",
       "0                  0.62349  \n",
       "1                  0.62349  \n",
       "2                  0.62349  \n",
       "3                  0.62349  \n",
       "4                  0.62349  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = extract_datetime_features(df3, 'date_time')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>date_time_year</th>\n",
       "      <th>date_time_month</th>\n",
       "      <th>...</th>\n",
       "      <th>date_time_hour</th>\n",
       "      <th>date_time_dayofweek</th>\n",
       "      <th>date_time_quarter</th>\n",
       "      <th>date_time_is_weekend</th>\n",
       "      <th>date_time_month_sin</th>\n",
       "      <th>date_time_month_cos</th>\n",
       "      <th>date_time_hour_sin</th>\n",
       "      <th>date_time_hour_cos</th>\n",
       "      <th>date_time_dayofweek_sin</th>\n",
       "      <th>date_time_dayofweek_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>288.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>5545</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>289.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>4516</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>289.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>4767</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>290.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>5026</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>291.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>4918</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   holiday    temp  rain_1h  snow_1h  clouds_all weather_main  \\\n",
       "0        0  288.28      0.0      0.0          40       Clouds   \n",
       "1        0  289.36      0.0      0.0          75       Clouds   \n",
       "2        0  289.58      0.0      0.0          90       Clouds   \n",
       "3        0  290.13      0.0      0.0          90       Clouds   \n",
       "4        0  291.14      0.0      0.0          75       Clouds   \n",
       "\n",
       "  weather_description  traffic_volume  date_time_year  date_time_month  ...  \\\n",
       "0    scattered clouds            5545            2012               10  ...   \n",
       "1       broken clouds            4516            2012               10  ...   \n",
       "2     overcast clouds            4767            2012               10  ...   \n",
       "3     overcast clouds            5026            2012               10  ...   \n",
       "4       broken clouds            4918            2012               10  ...   \n",
       "\n",
       "   date_time_hour  date_time_dayofweek  date_time_quarter  \\\n",
       "0               9                    1                  4   \n",
       "1              10                    1                  4   \n",
       "2              11                    1                  4   \n",
       "3              12                    1                  4   \n",
       "4              13                    1                  4   \n",
       "\n",
       "   date_time_is_weekend  date_time_month_sin  date_time_month_cos  \\\n",
       "0                 False            -0.866025                  0.5   \n",
       "1                 False            -0.866025                  0.5   \n",
       "2                 False            -0.866025                  0.5   \n",
       "3                 False            -0.866025                  0.5   \n",
       "4                 False            -0.866025                  0.5   \n",
       "\n",
       "   date_time_hour_sin  date_time_hour_cos  date_time_dayofweek_sin  \\\n",
       "0        7.071068e-01           -0.707107                 0.781831   \n",
       "1        5.000000e-01           -0.866025                 0.781831   \n",
       "2        2.588190e-01           -0.965926                 0.781831   \n",
       "3        1.224647e-16           -1.000000                 0.781831   \n",
       "4       -2.588190e-01           -0.965926                 0.781831   \n",
       "\n",
       "   date_time_dayofweek_cos  \n",
       "0                  0.62349  \n",
       "1                  0.62349  \n",
       "2                  0.62349  \n",
       "3                  0.62349  \n",
       "4                  0.62349  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['holiday'] = df3['holiday'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df5 - choose target and remove extra cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>hospdead</th>\n",
       "      <th>dzgroup</th>\n",
       "      <th>dzclass</th>\n",
       "      <th>num.co</th>\n",
       "      <th>edu</th>\n",
       "      <th>income</th>\n",
       "      <th>scoma</th>\n",
       "      <th>charges</th>\n",
       "      <th>...</th>\n",
       "      <th>bili</th>\n",
       "      <th>crea</th>\n",
       "      <th>sod</th>\n",
       "      <th>ph</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bun</th>\n",
       "      <th>urine</th>\n",
       "      <th>adlp</th>\n",
       "      <th>adls</th>\n",
       "      <th>adlsc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.84998</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>$11-$25k</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9715.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199982</td>\n",
       "      <td>1.199951</td>\n",
       "      <td>141.0</td>\n",
       "      <td>7.459961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.33899</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>Cirrhosis</td>\n",
       "      <td>COPD/CHF/Cirrhosis</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>$11-$25k</td>\n",
       "      <td>44.0</td>\n",
       "      <td>34496.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>132.0</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.74698</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>Cirrhosis</td>\n",
       "      <td>COPD/CHF/Cirrhosis</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>under $11k</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41094.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.199707</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>7.459961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.38498</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>under $11k</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3075.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.799927</td>\n",
       "      <td>139.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>79.88495</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>ARF/MOSF w/Sepsis</td>\n",
       "      <td>ARF/MOSF</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>50127.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.799927</td>\n",
       "      <td>143.0</td>\n",
       "      <td>7.509766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age     sex  hospdead            dzgroup             dzclass  num.co  \\\n",
       "1  62.84998    male         0        Lung Cancer              Cancer       0   \n",
       "2  60.33899  female         1          Cirrhosis  COPD/CHF/Cirrhosis       2   \n",
       "3  52.74698  female         0          Cirrhosis  COPD/CHF/Cirrhosis       2   \n",
       "4  42.38498  female         0        Lung Cancer              Cancer       2   \n",
       "5  79.88495  female         0  ARF/MOSF w/Sepsis            ARF/MOSF       1   \n",
       "\n",
       "    edu      income  scoma  charges  ...      bili      crea    sod        ph  \\\n",
       "1  11.0    $11-$25k    0.0   9715.0  ...  0.199982  1.199951  141.0  7.459961   \n",
       "2  12.0    $11-$25k   44.0  34496.0  ...       NaN  5.500000  132.0  7.250000   \n",
       "3  12.0  under $11k    0.0  41094.0  ...  2.199707  2.000000  134.0  7.459961   \n",
       "4  11.0  under $11k    0.0   3075.0  ...       NaN  0.799927  139.0       NaN   \n",
       "5   NaN         NaN   26.0  50127.0  ...       NaN  0.799927  143.0  7.509766   \n",
       "\n",
       "   glucose  bun  urine  adlp  adls  adlsc  \n",
       "1      NaN  NaN    NaN   7.0   7.0    7.0  \n",
       "2      NaN  NaN    NaN   NaN   1.0    1.0  \n",
       "3      NaN  NaN    NaN   1.0   0.0    0.0  \n",
       "4      NaN  NaN    NaN   0.0   0.0    0.0  \n",
       "5      NaN  NaN    NaN   NaN   2.0    2.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5_valid_targets = [\"hospdead\", \"death\", \"sfdm2\"]\n",
    "df5_target = df5_valid_targets[0]\n",
    "df5_columns_to_drop = [col for col in df5_valid_targets if col != df5_target] + ['slos', 'd.time']\n",
    "\n",
    "df5 = df5.drop(columns=df5_columns_to_drop)\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    (df1, 'scaled-sound-pressure'),\n",
    "    (df2, 'FloodProbability'),\n",
    "    (df3, 'traffic_volume'),\n",
    "    (df4, 'critical_temp'),\n",
    "    (df5, df5_target),\n",
    "    (df6, 'Trip_Price')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(df, target_column=None):\n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    \n",
    "    # duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"After removing duplicates: {df.shape}\")\n",
    "    \n",
    "    # columns with a single unique value\n",
    "    single_value_cols = [col for col in df.columns if df[col].nunique() <= 1]\n",
    "    df = df.drop(columns=single_value_cols)\n",
    "    if single_value_cols:\n",
    "        print(f\"Dropped columns with single value: {single_value_cols}\")\n",
    "    print(f\"After dropping single-value columns: {df.shape}\")\n",
    "    \n",
    "    # handle target column if is categorical\n",
    "    if target_column is not None:\n",
    "        is_categorical = df[target_column].dtype == 'object' or df[target_column].dtype == 'category' or df[target_column].dtype == 'bool'\n",
    "        is_categorical = is_categorical or (df[target_column].dtype.kind in 'ifu' and df[target_column].nunique() < 10)\n",
    "        \n",
    "        if is_categorical:\n",
    "            class_counts = df[target_column].value_counts()\n",
    "            classes_to_keep = class_counts[class_counts > 1].index\n",
    "            df = df[df[target_column].isin(classes_to_keep)]\n",
    "            print(f\"Target is categorical - after removing rare classes: {df.shape}\")\n",
    "        else:\n",
    "            print(f\"Target is continuous - skipping removal of rare classes\")\n",
    "    \n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "    \n",
    "    if target_column and target_column in numeric_cols:\n",
    "        numeric_cols.remove(target_column)\n",
    "    if target_column and target_column in categorical_cols:\n",
    "        categorical_cols.remove(target_column)\n",
    "    \n",
    "    binary_categorical_cols = [col for col in categorical_cols if df[col].nunique() == 2]\n",
    "    non_binary_categorical_cols = [col for col in categorical_cols if col not in binary_categorical_cols]\n",
    "    \n",
    "    print(f\"Numeric columns: {len(numeric_cols)}\")\n",
    "    print(f\"Binary categorical columns: {len(binary_categorical_cols)}\")\n",
    "    print(f\"Non-binary categorical columns: {len(non_binary_categorical_cols)}\")\n",
    "    \n",
    "    # Handle NaNs\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].fillna('missing')\n",
    "    \n",
    "    # one-hot encoding\n",
    "    if binary_categorical_cols or non_binary_categorical_cols:\n",
    "        if non_binary_categorical_cols:\n",
    "            df = pd.get_dummies(df, columns=non_binary_categorical_cols, dummy_na=False)\n",
    "        \n",
    "        if binary_categorical_cols:\n",
    "            df = pd.get_dummies(df, columns=binary_categorical_cols, drop_first=True, dummy_na=False)\n",
    "\n",
    "        dummy_cols = [col for col in df.columns if col not in numeric_cols + categorical_cols]\n",
    "        if target_column:\n",
    "            dummy_cols = [col for col in dummy_cols if col != target_column]\n",
    "        for col in dummy_cols:\n",
    "            if df[col].dtype == bool:\n",
    "                df[col] = df[col].astype(int)\n",
    "        \n",
    "        print(f\"Shape after one-hot encoding: {df.shape}\")\n",
    "    \n",
    "    if target_column:\n",
    "        X = df.drop(columns=[target_column])\n",
    "        y = df[target_column].copy()\n",
    "    else:\n",
    "        X = df.copy()\n",
    "        y = None\n",
    "    \n",
    "    # standarize numeric features\n",
    "    numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    if numeric_cols:\n",
    "        scaler = StandardScaler()\n",
    "        X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "    \n",
    "    if target_column:\n",
    "        processed_df = pd.concat([X, y], axis=1)\n",
    "    else:\n",
    "        processed_df = X\n",
    "    \n",
    "    print(f\"Final shape after preprocessing: {processed_df.shape}\")\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing dataset 1:\n",
      "Original shape: (1503, 6)\n",
      "After removing duplicates: (1503, 6)\n",
      "After dropping single-value columns: (1503, 6)\n",
      "Target is continuous - skipping removal of rare classes\n",
      "Numeric columns: 5\n",
      "Binary categorical columns: 0\n",
      "Non-binary categorical columns: 0\n",
      "Final shape after preprocessing: (1503, 6)\n",
      "First 5 rows of processed dataset 1:\n",
      "   frequency  angle_of_attack  chord-length  free-stream-velocity  \\\n",
      "0  -0.662023        -1.146403      1.799299              1.312935   \n",
      "1  -0.598561        -1.146403      1.799299              1.312935   \n",
      "2  -0.519235        -1.146403      1.799299              1.312935   \n",
      "3  -0.408177        -1.146403      1.799299              1.312935   \n",
      "4  -0.281255        -1.146403      1.799299              1.312935   \n",
      "\n",
      "   suction-side-displacement-thickness  scaled-sound-pressure  \n",
      "0                            -0.644805                126.201  \n",
      "1                            -0.644805                125.201  \n",
      "2                            -0.644805                125.951  \n",
      "3                            -0.644805                127.591  \n",
      "4                            -0.644805                127.461  \n",
      "\n",
      "Processing dataset 2:\n",
      "Original shape: (50000, 21)\n",
      "After removing duplicates: (50000, 21)\n",
      "After dropping single-value columns: (50000, 21)\n",
      "Target is continuous - skipping removal of rare classes\n",
      "Numeric columns: 20\n",
      "Binary categorical columns: 0\n",
      "Non-binary categorical columns: 0\n",
      "Final shape after preprocessing: (50000, 21)\n",
      "First 5 rows of processed dataset 2:\n",
      "   MonsoonIntensity  TopographyDrainage  RiverManagement  Deforestation  \\\n",
      "0         -0.890321            1.342509         0.441028       0.446084   \n",
      "1          1.345004           -0.438066        -0.007144       0.895983   \n",
      "2         -0.890321            2.232796        -0.455316      -1.803411   \n",
      "3         -0.443256           -0.438066        -1.351659       0.895983   \n",
      "4         -0.890321            0.897365        -0.007144      -1.353512   \n",
      "\n",
      "   Urbanization  ClimateChange  DamsQuality  Siltation  AgriculturalPractices  \\\n",
      "0     -0.440927      -0.443851     0.438597  -1.338607              -0.897767   \n",
      "1      0.896486       1.801586    -1.788597   0.005106              -0.002739   \n",
      "2      0.896486       0.005236    -0.452281   0.900915              -0.450253   \n",
      "3     -0.886732      -0.443851    -1.788597  -0.442798               0.444776   \n",
      "4      0.004877       1.352498    -0.006842  -1.338607               0.892290   \n",
      "\n",
      "   Encroachments  ...  DrainageSystems  CoastalVulnerability  Landslides  \\\n",
      "0      -1.341169  ...         2.231345              0.890080   -0.441806   \n",
      "1      -0.448954  ...         1.784535             -1.335031    0.455973   \n",
      "2       1.781585  ...         0.890914             -0.444987   -0.441806   \n",
      "3      -0.448954  ...        -0.449518             -1.335031    0.455973   \n",
      "4      -0.002846  ...         0.890914              0.445058    0.007083   \n",
      "\n",
      "   Watersheds  DeterioratingInfrastructure  PopulationScore  WetlandLoss  \\\n",
      "0   -1.334944                    -0.891125        -0.440066    -0.898457   \n",
      "1   -1.334944                    -1.787539        -1.780394     1.790031   \n",
      "2    1.353026                     0.453496        -1.780394     1.341950   \n",
      "3    0.457036                     1.349910         1.347039     0.445787   \n",
      "4   -0.886949                    -0.891125        -0.440066    -0.450375   \n",
      "\n",
      "   InadequatePlanning  PoliticalFactors  FloodProbability  \n",
      "0           -1.342769          0.449446             0.450  \n",
      "1           -1.791202         -0.886231             0.475  \n",
      "2           -0.894336          0.449446             0.515  \n",
      "3            0.450962          2.230349             0.520  \n",
      "4           -0.894336         -0.441005             0.475  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Processing dataset 3:\n",
      "Original shape: (48204, 21)\n",
      "After removing duplicates: (48187, 21)\n",
      "After dropping single-value columns: (48187, 21)\n",
      "Target is continuous - skipping removal of rare classes\n",
      "Numeric columns: 11\n",
      "Binary categorical columns: 1\n",
      "Non-binary categorical columns: 2\n",
      "Shape after one-hot encoding: (48187, 68)\n",
      "Final shape after preprocessing: (48187, 68)\n",
      "First 5 rows of processed dataset 3:\n",
      "    holiday      temp   rain_1h   snow_1h  clouds_all  date_time_year  \\\n",
      "0 -0.035602  0.530416 -0.007464 -0.027233   -0.240049            2012   \n",
      "1 -0.035602  0.611384 -0.007464 -0.027233    0.657047            2012   \n",
      "2 -0.035602  0.627877 -0.007464 -0.027233    1.041516            2012   \n",
      "3 -0.035602  0.669111 -0.007464 -0.027233    1.041516            2012   \n",
      "4 -0.035602  0.744831 -0.007464 -0.027233    0.657047            2012   \n",
      "\n",
      "   date_time_month  date_time_day  date_time_hour  date_time_dayofweek  ...  \\\n",
      "0               10              2               9                    1  ...   \n",
      "1               10              2              10                    1  ...   \n",
      "2               10              2              11                    1  ...   \n",
      "3               10              2              12                    1  ...   \n",
      "4               10              2              13                    1  ...   \n",
      "\n",
      "   weather_description_snow  weather_description_thunderstorm  \\\n",
      "0                         0                                 0   \n",
      "1                         0                                 0   \n",
      "2                         0                                 0   \n",
      "3                         0                                 0   \n",
      "4                         0                                 0   \n",
      "\n",
      "   weather_description_thunderstorm with drizzle  \\\n",
      "0                                              0   \n",
      "1                                              0   \n",
      "2                                              0   \n",
      "3                                              0   \n",
      "4                                              0   \n",
      "\n",
      "   weather_description_thunderstorm with heavy rain  \\\n",
      "0                                                 0   \n",
      "1                                                 0   \n",
      "2                                                 0   \n",
      "3                                                 0   \n",
      "4                                                 0   \n",
      "\n",
      "   weather_description_thunderstorm with light drizzle  \\\n",
      "0                                                  0     \n",
      "1                                                  0     \n",
      "2                                                  0     \n",
      "3                                                  0     \n",
      "4                                                  0     \n",
      "\n",
      "   weather_description_thunderstorm with light rain  \\\n",
      "0                                                 0   \n",
      "1                                                 0   \n",
      "2                                                 0   \n",
      "3                                                 0   \n",
      "4                                                 0   \n",
      "\n",
      "   weather_description_thunderstorm with rain  \\\n",
      "0                                           0   \n",
      "1                                           0   \n",
      "2                                           0   \n",
      "3                                           0   \n",
      "4                                           0   \n",
      "\n",
      "   weather_description_very heavy rain  date_time_is_weekend_True  \\\n",
      "0                                    0                          0   \n",
      "1                                    0                          0   \n",
      "2                                    0                          0   \n",
      "3                                    0                          0   \n",
      "4                                    0                          0   \n",
      "\n",
      "   traffic_volume  \n",
      "0            5545  \n",
      "1            4516  \n",
      "2            4767  \n",
      "3            5026  \n",
      "4            4918  \n",
      "\n",
      "[5 rows x 68 columns]\n",
      "\n",
      "Processing dataset 4:\n",
      "Original shape: (21263, 82)\n",
      "After removing duplicates: (21197, 82)\n",
      "After dropping single-value columns: (21197, 82)\n",
      "Target is continuous - skipping removal of rare classes\n",
      "Numeric columns: 81\n",
      "Binary categorical columns: 0\n",
      "Non-binary categorical columns: 0\n",
      "Final shape after preprocessing: (21197, 82)\n",
      "First 5 rows of processed dataset 4:\n",
      "   number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
      "0           -0.083643          0.047239             -0.450766   \n",
      "1            0.611647          0.174919             -0.431169   \n",
      "2           -0.083643          0.047239             -0.450092   \n",
      "3           -0.083643          0.047239             -0.450429   \n",
      "4           -0.083643          0.047239             -0.451440   \n",
      "\n",
      "   gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
      "0          -0.157843              -0.610639             0.041164   \n",
      "1           0.060653              -0.602992             0.774676   \n",
      "2          -0.157843              -0.610478             0.041164   \n",
      "3          -0.157843              -0.610559             0.041164   \n",
      "4          -0.157843              -0.610800             0.041164   \n",
      "\n",
      "   wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
      "0                -0.006747           0.131068              -0.052257   \n",
      "1                -0.018313           0.131068               0.109691   \n",
      "2                -0.222130           0.131068               0.094084   \n",
      "3                -0.106705           0.131068               0.020914   \n",
      "4                 0.159817           0.131068              -0.198597   \n",
      "\n",
      "   std_atomic_mass  ...  wtd_mean_Valence  gmean_Valence  wtd_gmean_Valence  \\\n",
      "0         0.376259  ...         -0.749433      -0.803339          -0.708921   \n",
      "1         0.132784  ...         -0.749433      -1.114640          -0.716681   \n",
      "2         0.376259  ...         -0.737427      -0.803339          -0.697929   \n",
      "3         0.376259  ...         -0.743430      -0.803339          -0.703433   \n",
      "4         0.376259  ...         -0.761440      -0.803339          -0.719849   \n",
      "\n",
      "   entropy_Valence  wtd_entropy_Valence  range_Valence  wtd_range_Valence  \\\n",
      "0         0.183039             0.032211      -0.838596          -0.404263   \n",
      "1         0.662110            -0.017774      -0.034228          -0.360420   \n",
      "2         0.183039            -0.065251      -0.838596          -0.375034   \n",
      "3         0.183039            -0.013531      -0.838596          -0.389649   \n",
      "4         0.183039             0.110690      -0.838596          -0.433491   \n",
      "\n",
      "   std_Valence  wtd_std_Valence  critical_temp  \n",
      "0     -0.83853        -0.519945           29.0  \n",
      "1     -0.42730        -0.450766           26.0  \n",
      "2     -0.83853        -0.503197           19.0  \n",
      "3     -0.83853        -0.511408           22.0  \n",
      "4     -0.83853        -0.538035           23.0  \n",
      "\n",
      "[5 rows x 82 columns]\n",
      "\n",
      "Processing dataset 5:\n",
      "Original shape: (9105, 43)\n",
      "After removing duplicates: (9105, 43)\n",
      "After dropping single-value columns: (9105, 43)\n",
      "Target is categorical - after removing rare classes: (9105, 43)\n",
      "Numeric columns: 35\n",
      "Binary categorical columns: 1\n",
      "Non-binary categorical columns: 6\n",
      "Shape after one-hot encoding: (9105, 67)\n",
      "Final shape after preprocessing: (9105, 67)\n",
      "First 5 rows of processed dataset 5:\n",
      "        age    num.co       edu     scoma   charges  totcst  totmcst  \\\n",
      "1  0.012772 -1.390013 -0.239424 -0.489508 -0.494554     0.0      0.0   \n",
      "2 -0.148262  0.097711  0.080794  1.296642 -0.250812     0.0      0.0   \n",
      "3 -0.635153  0.097711  0.080794 -0.489508 -0.185915     0.0      0.0   \n",
      "4 -1.299688  0.097711 -0.239424 -0.489508 -0.559864     0.0      0.0   \n",
      "5  1.105258 -0.646151  0.000000  0.565944 -0.097068     0.0      0.0   \n",
      "\n",
      "    avtisst       sps       aps  ...  race_white  ca_metastatic  ca_no  \\\n",
      "1 -1.185089  0.845860 -0.884247  ...           0              1      0   \n",
      "2  0.485020  2.744862  1.829094  ...           1              0      1   \n",
      "3 -0.729604 -0.507752  0.371930  ...           1              0      1   \n",
      "4 -1.185089 -0.548399 -0.934494  ...           1              1      0   \n",
      "5 -0.299426 -0.204669 -0.381776  ...           1              0      1   \n",
      "\n",
      "   ca_yes  dnr_dnr after sadm  dnr_dnr before sadm  dnr_missing  dnr_no dnr  \\\n",
      "1       0                   0                    0            0           1   \n",
      "2       0                   0                    0            1           0   \n",
      "3       0                   0                    0            0           1   \n",
      "4       0                   0                    0            0           1   \n",
      "5       0                   0                    0            0           1   \n",
      "\n",
      "   sex_male  hospdead  \n",
      "1         1         0  \n",
      "2         0         1  \n",
      "3         0         0  \n",
      "4         0         0  \n",
      "5         0         0  \n",
      "\n",
      "[5 rows x 67 columns]\n",
      "\n",
      "Processing dataset 6:\n",
      "Original shape: (1000, 11)\n",
      "After removing duplicates: (1000, 11)\n",
      "After dropping single-value columns: (1000, 11)\n",
      "Target is continuous - skipping removal of rare classes\n",
      "Numeric columns: 6\n",
      "Binary categorical columns: 1\n",
      "Non-binary categorical columns: 3\n",
      "Shape after one-hot encoding: (1000, 22)\n",
      "Final shape after preprocessing: (1000, 22)\n",
      "First 5 rows of processed dataset 6:\n",
      "   Trip_Distance_km  Passenger_Count  Base_Fare  Per_Km_Rate  Per_Minute_Rate  \\\n",
      "0     -3.981496e-01         0.487214   0.067255    -1.034878         0.240523   \n",
      "1      1.058191e+00        -1.375375   0.000000    -1.464767         1.217383   \n",
      "2      5.053590e-01        -1.375375  -0.947276    -0.055685        -1.269171   \n",
      "3      1.680904e-01         1.418509  -0.027120    -1.727477        -1.269171   \n",
      "4      1.832139e-16         0.487214  -0.675948    -1.440884         0.240523   \n",
      "\n",
      "   Trip_Duration_Minutes  Time_of_Day_Afternoon  Time_of_Day_Evening  \\\n",
      "0              -0.264915                      0                    0   \n",
      "1              -0.687916                      1                    0   \n",
      "2              -0.793268                      0                    1   \n",
      "3               1.746020                      0                    1   \n",
      "4              -1.260326                      0                    1   \n",
      "\n",
      "   Time_of_Day_Morning  Time_of_Day_Night  ...  Traffic_Conditions_Low  \\\n",
      "0                    1                  0  ...                       1   \n",
      "1                    0                  0  ...                       0   \n",
      "2                    0                  0  ...                       0   \n",
      "3                    0                  0  ...                       1   \n",
      "4                    0                  0  ...                       0   \n",
      "\n",
      "   Traffic_Conditions_Medium  Traffic_Conditions_missing  Weather_Clear  \\\n",
      "0                          0                           0              1   \n",
      "1                          0                           0              1   \n",
      "2                          0                           0              1   \n",
      "3                          0                           0              0   \n",
      "4                          0                           0              1   \n",
      "\n",
      "   Weather_Rain  Weather_Snow  Weather_missing  Day_of_Week_Weekend  \\\n",
      "0             0             0                0                    0   \n",
      "1             0             0                0                    0   \n",
      "2             0             0                0                    1   \n",
      "3             0             0                1                    0   \n",
      "4             0             0                0                    0   \n",
      "\n",
      "   Day_of_Week_missing  Trip_Price  \n",
      "0                    0     36.2624  \n",
      "1                    0         NaN  \n",
      "2                    0     52.9032  \n",
      "3                    0     36.4698  \n",
      "4                    0     15.6180  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "processed_dfs = []\n",
    "for i, (df, target) in enumerate(datasets):\n",
    "    print(f\"\\nProcessing dataset {i+1}:\")\n",
    "    processed_df = preprocess_dataset(df, target)\n",
    "    processed_dfs.append(processed_df)\n",
    "    print(f\"First 5 rows of processed dataset {i+1}:\")\n",
    "    print(processed_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 saved to ./../processed_data/preprocessed_data_jrsh\\airfoil_self_noise_processed.csv\n",
      "Shape: (1503, 6)\n",
      "Dataset 2 saved to ./../processed_data/preprocessed_data_jrsh\\flood_probability_processed.csv\n",
      "Shape: (50000, 21)\n",
      "Dataset 3 saved to ./../processed_data/preprocessed_data_jrsh\\traffic_volume_processed.csv\n",
      "Shape: (48187, 68)\n",
      "Dataset 4 saved to ./../processed_data/preprocessed_data_jrsh\\critical_temp_processed.csv\n",
      "Shape: (21197, 82)\n",
      "Dataset 5 saved to ./../processed_data/preprocessed_data_jrsh\\support2_processed.csv\n",
      "Shape: (9105, 67)\n",
      "Dataset 6 saved to ./../processed_data/preprocessed_data_jrsh\\taxi_trip_processed.csv\n",
      "Shape: (1000, 22)\n"
     ]
    }
   ],
   "source": [
    "output_dir = './../processed_data/preprocessed_data_jrsh'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "dataset_names = [\n",
    "    'airfoil_self_noise',\n",
    "    'flood_probability',\n",
    "    'traffic_volume',\n",
    "    'critical_temp',\n",
    "    'support2',\n",
    "    'taxi_trip'\n",
    "]\n",
    "\n",
    "for i, (df_processed, name) in enumerate(zip(processed_dfs, dataset_names)):\n",
    "    output_path = os.path.join(output_dir, f\"{name}_processed.csv\")\n",
    "    df_processed.to_csv(output_path, index=False)\n",
    "    print(f\"Dataset {i+1} saved to {output_path}\")\n",
    "    print(f\"Shape: {df_processed.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

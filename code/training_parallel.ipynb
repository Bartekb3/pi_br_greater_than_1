{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9018942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.base import clone\n",
    "import ast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecddbd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modele takie same jak w oryginale, wyrzuciłem jedynie kryterium podziału bo w regresji to jest po prostu mse\n",
    "\n",
    "########################################### MODELS ##########################################\n",
    "cpu_no = 12\n",
    "rf_100 =    ('RF[100]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, n_estimators=100))\n",
    "rf_200 =    ('RF[200]', RandomForestRegressor(random_state=123, n_jobs=cpu_no,  n_estimators=200))\n",
    "rf_500 =    ('RF[500]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, n_estimators=500))\n",
    "#rf_entr =   ('  RF[entr]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, criterion=\"entropy\"))\n",
    "rf_md_10 =  ('RF[md10]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, max_depth=10))\n",
    "rf_md_15 =  ('RF[md15]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, max_depth=15))\n",
    "rf_md_20 =  ('RF[md20]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, max_depth=20))\n",
    "rf_md_25 =  ('RF[md25]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, max_depth=25))\n",
    "rf_mss_3 =  ('RF[mss3]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, min_samples_split=3))\n",
    "rf_mss_4 =  ('RF[mss4]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, min_samples_split=4))\n",
    "rf_mss_6 =  ('RF[mss6]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, min_samples_split=6))\n",
    "rf_mss_8 =  ('RF[mss8]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, min_samples_split=8))\n",
    "rf_msl_2 =  ('RF[msl2]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, min_samples_leaf=2))\n",
    "rf_msl_3 =  ('RF[msl3]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, min_samples_leaf=3))\n",
    "rf_msl_4 =  ('RF[msl4]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, min_samples_leaf=4))\n",
    "rf_msl_5 =  ('RF[msl5]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, min_samples_leaf=5))\n",
    "rf_mf_log = ('RF[mfLog2]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, max_features=\"log2\"))\n",
    "rf_mf_all = ('RF[mfAll]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, max_features=None))\n",
    "######################################## END OF MODELS ######################################\n",
    "\n",
    "######################################### PARAMETERS ########################################\n",
    "max_samples = [0.2, 0.6, 0.8, 1, 1.2, 2, 3, 4, 5]\n",
    "forests = [rf_100, rf_200, rf_500, rf_md_10, rf_md_15, rf_md_20, rf_md_25, rf_mss_3, rf_mss_4, rf_mss_6, rf_mss_8,\n",
    "        rf_msl_2, rf_msl_3, rf_msl_4, rf_msl_5, rf_mf_log, rf_mf_all]\n",
    "\n",
    "##################################### END OF PARAMETERS #####################################\n",
    "\n",
    "#duplikujemy dane zeby dalo sie zrobic br>1\n",
    "def make_X_train(X_tra, y_tra, max_sample):\n",
    "    if max_sample <= 1:\n",
    "        return X_tra, y_tra\n",
    "    elif 1 < max_sample < 2:\n",
    "        return np.tile(X_tra, (2, 1)), np.tile(y_tra, 2)\n",
    "    else:\n",
    "        return np.tile(X_tra, (max_sample, 1)), np.tile(y_tra, max_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "397fe044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to zrobcie tak jak tutaj albo wpiszcie ręcznie do dataset_paths sciezki do datasetow\n",
    "\n",
    "path_to_datasets = '../test_data' #'path/to/folder/with/datasets'\n",
    "\n",
    "dataset_paths = []\n",
    "for filename in os.listdir(path_to_datasets):\n",
    "    full_path = os.path.join(path_to_datasets, filename)\n",
    "    dataset_paths.append(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "083ad630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fold(train_index, test_index, X, y, ms, rfr):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    X_tr, y_tr = make_X_train(X_train, y_train, ms)\n",
    "\n",
    "    rfr_fold = clone(rfr[1])\n",
    "    rfr_fold.max_samples = None if ms >= 1 and ms != 1.2 else (0.6 if ms == 1.2 else ms)\n",
    "    rfr_fold.fit(X_tr, y_tr)\n",
    "\n",
    "    y_hat = rfr_fold.predict(X_test)\n",
    "    return mean_squared_error(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6504524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../test_data\\Abalone_1_preprocessed.csv with bootstrap rate 5 and model RF[100]  ...\n",
      "Processing ../test_data\\Abalone_1_preprocessed.csv with bootstrap rate 5 and model RF[200]  ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rfr \u001b[38;5;129;01min\u001b[39;00m forests:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with bootstrap rate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrfr[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m     cv_mse_scores \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_fold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrfr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcvsplit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(dataset_path)\n\u001b[0;32m     29\u001b[0m     results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(ms)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = {'dataset' : [],\n",
    "           'bootstrap_rate': [],\n",
    "           'rf' : [],\n",
    "           'cv_mse_scores' : [],\n",
    "           'mean_mse' : [],\n",
    "           'std_mse' : []}\n",
    "\n",
    "scaler = StandardScaler()\n",
    "cvsplit = RepeatedKFold(n_splits=2, n_repeats=200, random_state=42)\n",
    "\n",
    "for dataset_path in dataset_paths:\n",
    "    df = pd.read_csv(dataset_path)\n",
    "\n",
    "    X = df.iloc[:, :-1].to_numpy()\n",
    "    y = df.iloc[:, -1].to_numpy()\n",
    "\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    for ms in max_samples:\n",
    "        for rfr in forests:\n",
    "            print(f'Processing {dataset_path} with bootstrap rate {ms} and model {rfr[0]}  ...')\n",
    "\n",
    "            cv_mse_scores = Parallel(n_jobs=-1)(\n",
    "                delayed(process_fold)(train_index, test_index, X, y, ms, rfr)\n",
    "                for train_index, test_index in cvsplit.split(X, y)\n",
    "            )\n",
    "\n",
    "            results['dataset'].append(dataset_path)\n",
    "            results['bootstrap_rate'].append(ms)\n",
    "            results['rf'].append(rfr[0])\n",
    "            results['cv_mse_scores'].append(cv_mse_scores)\n",
    "            results['mean_mse'].append(f'{np.mean(cv_mse_scores):.3f}')\n",
    "            results['std_mse'].append(f'{np.std(cv_mse_scores):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wyniki = pd.DataFrame(results)\n",
    "wyniki.to_csv('../results/wyniki_bb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060dd11a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwyniki_bb.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m res\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "res = pd.read_csv('../results/wyniki_bb.csv')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e93e3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "string = res['cv_mse_scores'].iloc[0]\n",
    "lista = ast.literal_eval(string)\n",
    "\n",
    "len(lista)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9018942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecddbd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modele takie same jak w oryginale, wyrzuciłem jedynie kryterium podziału bo w regresji to jest po prostu mse\n",
    "\n",
    "########################################### MODELS ##########################################\n",
    "cpu_no = 12\n",
    "rf_100 =    ('RF', RandomForestRegressor(random_state=123, n_jobs=cpu_no, n_estimators=100))\n",
    "rf_200 =    ('RF[200]', RandomForestRegressor(random_state=123, n_jobs=cpu_no,  n_estimators=200))\n",
    "rf_500 =    ('RF[500]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, n_estimators=500))\n",
    "#rf_entr =   ('  RF[entr]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, criterion=\"entropy\"))\n",
    "rf_md_10 =  ('RF[md10]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, max_depth=10))\n",
    "rf_md_15 =  ('RF[md15]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, max_depth=15))\n",
    "rf_md_20 =  ('RF[md20]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, max_depth=20))\n",
    "rf_md_25 =  ('RF[md25]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, max_depth=25))\n",
    "rf_mss_3 =  ('RF[mss3]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, min_samples_split=3))\n",
    "rf_mss_4 =  ('RF[mss4]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, min_samples_split=4))\n",
    "rf_mss_6 =  ('RF[mss6]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, min_samples_split=6))\n",
    "rf_mss_8 =  ('RF[mss8]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, min_samples_split=8))\n",
    "rf_msl_2 =  ('RF[msl2]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, min_samples_leaf=2))\n",
    "rf_msl_3 =  ('RF[msl3]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, min_samples_leaf=3))\n",
    "rf_msl_4 =  ('RF[msl4]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, min_samples_leaf=4))\n",
    "rf_msl_5 =  ('RF[msl5]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, min_samples_leaf=5))\n",
    "rf_mf_log = ('RF[mfLog2]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, max_features=\"log2\"))\n",
    "rf_mf_all = ('RF[mfAll]', RandomForestRegressor(random_state=123, n_jobs=cpu_no, max_features=None))\n",
    "######################################## END OF MODELS ######################################\n",
    "\n",
    "######################################### PARAMETERS ########################################\n",
    "max_samples = [0.2, 0.6, 0.8, 1, 1.2, 2, 3, 4, 5]\n",
    "forests = [rf_100, rf_200, rf_500, rf_md_10, rf_md_15, rf_md_20, rf_md_25, rf_mss_3, rf_mss_4, rf_mss_6, rf_mss_8,\n",
    "        rf_msl_2, rf_msl_3, rf_msl_4, rf_msl_5, rf_mf_log, rf_mf_all]\n",
    "##################################### END OF PARAMETERS #####################################\n",
    "\n",
    "#duplikujemy dane zeby dalo sie zrobic br>1\n",
    "def make_X_train(X_tra, y_tra, max_sample):\n",
    "    if max_sample <= 1:\n",
    "        return X_tra, y_tra\n",
    "    elif 1 < max_sample < 2:\n",
    "        return np.tile(X_tra, (2, 1)), np.tile(y_tra, 2)\n",
    "    else:\n",
    "        return np.tile(X_tra, (max_sample, 1)), np.tile(y_tra, max_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "397fe044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to zrobcie tak jak tutaj albo wpiszcie ręcznie do dataset_paths sciezki do datasetow\n",
    "\n",
    "path_to_datasets = './preprocessed_data_mis_not_standarized' #'path/to/folder/with/datasets'\n",
    "\n",
    "dataset_paths = []\n",
    "for filename in os.listdir(path_to_datasets):\n",
    "    full_path = os.path.join(path_to_datasets, filename)\n",
    "    dataset_paths.append(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d55c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'dataset' : [],\n",
    "           'bootstrap_rate': [],\n",
    "           'rf' : [],\n",
    "           'cv_mse_scores' : [],\n",
    "           'mean_mse' : [],\n",
    "           'std_mse' : []}\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "cvsplit = RepeatedKFold(n_splits=2, n_repeats=200, random_state=42)\n",
    "\n",
    "\n",
    "for dataset_path in dataset_paths:\n",
    "    \n",
    "    df = pd.read_csv(dataset_path) #jesli w csv jest kolumna z indeksami to uzyjcie pd.read_csv(dataset_path, index_col=False)\n",
    "    \n",
    "    X = df.iloc[:, :-1].to_numpy()\n",
    "    y = df.iloc[:, -1].to_numpy()\n",
    "\n",
    "    X = standard_scaler.fit_transform(X) #nie wiem po co ale tak robili w paperze \n",
    "\n",
    "    for ms in max_samples:\n",
    "\n",
    "        for rfr in forests: \n",
    "            cv_mse_scores = []\n",
    "\n",
    "            for train_index, test_index in cvsplit.split(X, y):\n",
    "            \n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "                \n",
    "                X_tr, y_tr = make_X_train(X_train, y_train, ms)\n",
    "\n",
    "                rfr[1].max_samples = None if ms >= 1 and ms != 1.2 else (0.6 if ms == 1.2 else ms)\n",
    "                rfr[1].fit(X_tr, y_tr)\n",
    "                \n",
    "                y_hat = rfr[1].predict(X_test)\n",
    "                mse = mean_squared_error(y_test, y_hat)\n",
    "                cv_mse_scores.append(mse)\n",
    "                \n",
    "            \n",
    "            results['dataset'].append(dataset_path)\n",
    "            results['bootstrap_rate'].append(ms)\n",
    "            results['rf'].append(rfr[0])\n",
    "            results['cv_mse_scores'].append(cv_mse_scores)\n",
    "            results['mean_mse'].append(f'{np.mean(cv_mse_scores):.3f}')\n",
    "            results['std_mse'].append(f'{np.std(cv_mse_scores):.3f}')\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9ba9418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wyniki = pd.DataFrame(results)\n",
    "wyniki.to_csv('wyniki_misiu.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
